{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sourmash algorithms and implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topics:\n",
    "    \n",
    "* modulo hash, \"density hashing\",\n",
    "    * https://github.com/dib-lab/sourmash/issues/823\n",
    "    * https://github.com/dib-lab/sourmash/issues/606\n",
    "    * https://github.com/richarddurbin/modimizer\n",
    "* 'scaled' implementation, and using scaled hashes for Jaccard similarity and containment calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49970"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import screed\n",
    "\n",
    "def kmerize_seq(sequence, k=31):\n",
    "    sequence = sequence.upper()\n",
    "    for start in range(0, len(sequence) - k + 1):\n",
    "        kmer = sequence[start:start+k]\n",
    "        \n",
    "        # canonicalize the k-mer\n",
    "        revcomp = screed.rc(kmer)\n",
    "        if kmer < revcomp:\n",
    "            yield kmer\n",
    "        else:\n",
    "            yield revcomp\n",
    "            \n",
    "#list(kmerize('ATGGACAGAGATG', k=2))\n",
    "\n",
    "def kmerize_file(filename, k=31):\n",
    "    # walk through every record in a FASTA/FASTQ file\n",
    "    for record in screed.open(filename):\n",
    "        # k-merize each sequence\n",
    "        for kmer in kmerize_seq(record.sequence[:50000]):\n",
    "            # return canonical version of each k-mer\n",
    "            yield kmer\n",
    "\n",
    "len(set(kmerize_file('data/genomes/2.fa')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3\n",
    "\n",
    "# implementation of a minhash bottom sketch, where a fixed number\n",
    "# of hashes is kept for each input set of k-mers.\n",
    "\n",
    "# there's a bug in this code where we are not handling duplicate k-mers\n",
    "# properly.\n",
    "def minhash(kmers, num=500):\n",
    "    basket = []\n",
    "    for kmer in kmers:\n",
    "        hashval = mmh3.hash64(kmer, seed=42)[0]\n",
    "        if hashval < 0:\n",
    "            hashval += 2**64\n",
    "        \n",
    "        # basket not full? add hash value\n",
    "        if len(basket) < num:\n",
    "            basket.append(hashval)\n",
    "            basket = list(sorted(basket))\n",
    "        # basket full?\n",
    "        elif len(basket) == num:\n",
    "            if basket[-1] > hashval:\n",
    "                # this hashvalue does not belong in basket\n",
    "                pass\n",
    "            else:\n",
    "                # is new hash value less than largest? if so, evict.\n",
    "                basket.pop()\n",
    "                basket.append(hashval)\n",
    "                basket = list(sorted(basket))\n",
    "                \n",
    "    return basket\n",
    "\n",
    "b_all = set(kmerize_file('data/genomes/2.fa'))\n",
    "c_all = set(kmerize_file('data/genomes/47.fa'))\n",
    "d_all = set(kmerize_file('data/genomes/63.fa'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = minhash(b_all, num=1000)\n",
    "c = minhash(c_all, num=1000)\n",
    "d = minhash(d_all, num=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49970 96808 169296\n",
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(b_all), len(c_all), len(d_all))\n",
    "print(len(b), len(c), len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'set'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(b_all))\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_all to b_all 1.0\n",
      "b to b 1.0\n",
      "b_all to c_all 0.0\n",
      "b to c 0.0\n",
      "c_all to d_all 0.2544146624303506\n",
      "c to d 0.1607661056297156\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(x, y):\n",
    "    x = set(x)\n",
    "    intersection = x.intersection(y)\n",
    "    union = x.union(y)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "print('b_all to b_all', jaccard_similarity(b_all, b_all))\n",
    "print('b to b', jaccard_similarity(b, b))\n",
    "\n",
    "print('b_all to c_all', jaccard_similarity(b_all, c_all))\n",
    "print('b to c', jaccard_similarity(b, c))\n",
    "\n",
    "print('c_all to d_all', jaccard_similarity(c_all, d_all))\n",
    "print('c to d', jaccard_similarity(c, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now instead of a minhash, implement a scaled sketch, which is what\n",
    "# we recommend using in sourmash.\n",
    "\n",
    "# scaled here is 1/f of k-mers that we are going to keep\n",
    "# this is a sampling mechanism where we \"stochastically\" sample\n",
    "# by randomizing the order of k-mers with a hash function, and\n",
    "# then choosing a subset of them deterministically.\n",
    "\n",
    "def scaledhash(kmers, scaled=1000):\n",
    "    basket = set()\n",
    "    \n",
    "    MAX_HASH=2**64 - 1\n",
    "    boundary = MAX_HASH / scaled\n",
    "    \n",
    "    for kmer in kmers:\n",
    "        hashval = mmh3.hash64(kmer, seed=42)[0]\n",
    "        if hashval < 0:\n",
    "            hashval += 2**64\n",
    "            \n",
    "        # accept any k-mer that hashes into the bottom 1/scaled of the\n",
    "        # hash space. what this should do (for a good hash function)\n",
    "        # is pick approximately 1 in 'scaled' of the input k-mers.\n",
    "        if hashval < boundary:\n",
    "            basket.add(hashval)\n",
    "\n",
    "    return basket\n",
    "        \n",
    "b_sh = scaledhash(b_all, scaled=1000)\n",
    "c_sh = scaledhash(c_all, scaled=1000)\n",
    "d_sh = scaledhash(d_all, scaled=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_all to b_all 1.0\n",
      "b to b 1.0\n",
      "b_sh to b_sh 1.0\n",
      "b_all to c_all 0.0\n",
      "b to c 0.0\n",
      "b_sh to c_sh 0.0\n",
      "c_all to d_all 0.2544146624303506\n",
      "c to d 0.1607661056297156\n",
      "c_sh to dsh 0.1889400921658986\n"
     ]
    }
   ],
   "source": [
    "print('b_all to b_all', jaccard_similarity(b_all, b_all))\n",
    "print('b to b', jaccard_similarity(b, b))\n",
    "print('b_sh to b_sh', jaccard_similarity(b_sh, b_sh))\n",
    "\n",
    "\n",
    "print('b_all to c_all', jaccard_similarity(b_all, c_all))\n",
    "print('b to c', jaccard_similarity(b, c))\n",
    "print('b_sh to c_sh', jaccard_similarity(b_sh, c_sh))\n",
    "\n",
    "print('c_all to d_all', jaccard_similarity(c_all, d_all))\n",
    "print('c to d', jaccard_similarity(c, d))\n",
    "print('c_sh to dsh', jaccard_similarity(c_sh, d_sh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics:\n",
    "    \n",
    "* modulo hash, \"density hashing\",\n",
    "    * https://github.com/dib-lab/sourmash/issues/823\n",
    "    * https://github.com/dib-lab/sourmash/issues/606\n",
    "    * https://github.com/richarddurbin/modimizer\n",
    "* 'scaled' implementation, and using scaled hashes for Jaccard similarity and containment calculations\n",
    "    * with a scaled of 10,000, you get approximately 1 hash per every 10kb of sequence\n",
    "    * see [graph at 10kb](https://github.com/dib-lab/charcoal/blob/master/stats/stats10k.png), [graph at 5kb](https://github.com/dib-lab/charcoal/blob/master/stats/stats5k.png)\n",
    "    * (similar statistics apply on a stream of distinct k-mers)\n",
    "* looking in more depth at the signatures\n",
    "* manipulating signatures (command line, Python, etc.)\n",
    "* downsampling in particular\n",
    "* ...hash matches do indeed correspond to nucleotide alignments!\n",
    "* downsides of scaled approach:\n",
    "    * don't work for small genomes\n",
    "    * arbitrary growth in size (so may be unnecessarily large for large genomes!)\n",
    "    \n",
    "tl;dr sourmash is basically many thousands of lines of code around doing this stuff with reasonable efficiency and care."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
